{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import random\n",
    "\n",
    "from CTL2.causal_tree_learn import CausalTree\n",
    "from DGP.DGP import dgp2\n",
    "from DGP.DGP import dgp2train\n",
    "from DGP.DGP import dgp2test\n",
    "from DGP.DGP import dgp4\n",
    "from DGP.DGP import dgp4int\n",
    "from DGP.DGP import dgp8\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "#from notify_run import Notify \n",
    "#notify = Notify()\n",
    "import datetime\n",
    "\n",
    "from utility.utility import transposer as tp\n",
    "from utility.utility import writer\n",
    "from utility.utility import reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_ate2_test(n, tsize, var_e, reps, nomin_test):\n",
    "    #true ATE\n",
    "    tauhat = np.zeros((tsize, 1))\n",
    "    #true ITE\n",
    "    x_test, y_test, treat_test = dgp2test(tsize,var_e)\n",
    "    for i in range(reps):\n",
    "        x_train, y_train, treat_train = dgp2train(n, var_e)\n",
    "        tau = np.where((x_test[:,0] >= 0),1.5, -1.5)\n",
    "        ctl = CausalTree(honest=True, weight=0.0, split_size=0.0, max_depth = 3) #which type of tree to call\n",
    "        ctl.fit(x_train, y_train, treat_train, nomin_test = nomin_test) #select est size when fitting\n",
    "        ctl.prune()\n",
    "        ctl_predict = ctl.predict(x_test)\n",
    "        #predicted ATE\n",
    "        tauhat = np.append(tauhat, ctl_predict.reshape(-1,1), axis = 1)\n",
    "\n",
    "    #TOTAL MSE's\n",
    "    ind_var = np.var(tauhat[:, 1:], axis = 1)\n",
    "    ind_mean = np.mean(tauhat, axis = 1)\n",
    "\n",
    "    total_var = np.sum(ind_var)/tsize\n",
    "    total_bias = np.sum(np.square(np.subtract(ind_mean, tau)))/tsize\n",
    "    total_mse = total_var + total_bias\n",
    "    results = np.concatenate([np.array([nomin_test]), np.array([total_bias]), np.array([total_var]), np.array([total_mse])])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_ate2(n, tsize, var_e, reps, nomin_test):\n",
    "    #true ATE\n",
    "    ATE1 = np.ones(reps)*1.5\n",
    "    ATE2 = np.ones(reps)*-1.5\n",
    "    #predicted ATE\n",
    "    ate1 = []\n",
    "    ate2 = []\n",
    "    #ITE dummy\n",
    "    tauhat = np.zeros((tsize, 1))\n",
    "    #true ITE\n",
    "\n",
    "    for i in range(reps):\n",
    "        x_train, x_test, y_train, y_test, treat_train, treat_test = dgp2(n, tsize, var_e)\n",
    "        tau = np.where((x_test[:,0] >= 0),1.5, -1.5)\n",
    "        ctl = CausalTree(honest=True, weight=0.0, split_size=0.0, max_depth = 3) #which type of tree to call\n",
    "        ctl.fit(x_train, y_train, treat_train, nomin_test = nomin_test) #select est size when fitting\n",
    "        ctl.prune()\n",
    "        ctl_predict = ctl.predict(x_test)\n",
    "        #predicted ATE\n",
    "        ate1 = np.append(ate1, np.mean(ctl_predict[np.where(x_test[:,0] >= 0)]))\n",
    "        ate2 = np.append(ate2, np.mean(ctl_predict[np.where(x_test[:,0] < 0)]))\n",
    "        #predicted ITE\n",
    "        tauhat = np.append(tauhat, ctl_predict.reshape(-1,1), axis = 1)\n",
    "\n",
    "    mean_ate = np.array([np.mean(ate1), np.mean(ate2)])    \n",
    "    mse_ate = np.array([mse(ATE1, ate1), mse(ATE2, ate2)])\n",
    "    bias_ate = np.array([np.sum(np.subtract(ATE1,ate1))/reps, np.sum(np.subtract(ATE2,ate2))/reps])\n",
    "    var_ate = np.array([np.var(ate1), np.var(ate2)])\n",
    "\n",
    "    #TOTAL MSE's\n",
    "    ind_var = np.var(tauhat[:, 1:], axis = 1)\n",
    "    ind_mean = np.mean(tauhat, axis = 1)\n",
    "\n",
    "    total_var = np.sum(ind_var)/tsize\n",
    "    total_bias = np.sum(np.square(np.subtract(ind_mean, tau)))/tsize\n",
    "    total_mse = total_var + total_bias\n",
    "\n",
    "    results = np.concatenate([np.array([nomin_test]), mean_ate, bias_ate, var_ate, mse_ate, np.array([total_bias]), np.array([total_var]), np.array([total_mse])])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "tsize = 3000\n",
    "reps = 500\n",
    "test_sizes = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "res = []\n",
    "var = [0.01, 1.0, 2.5]\n",
    "\n",
    "#print(\"start time: \", str(datetime.datetime.now())[11:16])\n",
    "\n",
    "for v in var:\n",
    "    df = pd.DataFrame()\n",
    "    for size in test_sizes:\n",
    "        results = mc_ate2_test(n, tsize, v, reps, size)\n",
    "        df = pd.concat([df, pd.DataFrame(results).transpose()])\n",
    "    df.columns=['test_sizes', 'MSE_T_BIAS', 'MSE_T_VAR', 'MSE_TOTAL']\n",
    "    res.append([v])\n",
    "    res.append([df])\n",
    "    \n",
    "#print(\"end time: \", str(datetime.datetime.now())[11:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.01],\n",
       " [   test_sizes  MSE_T_BIAS  MSE_T_VAR  MSE_TOTAL\n",
       "  0         0.2    0.136339   0.506717   0.643056\n",
       "  0         0.3    0.075862   0.422587   0.498449\n",
       "  0         0.4    0.086525   0.247190   0.333715\n",
       "  0         0.5    0.076038   0.248323   0.324360\n",
       "  0         0.6    0.130646   0.337726   0.468372\n",
       "  0         0.7    0.083239   0.237470   0.320709\n",
       "  0         0.8    0.280659   0.452722   0.733381\n",
       "  0         0.9    0.635079   0.674585   1.309664],\n",
       " [1.0],\n",
       " [   test_sizes  MSE_T_BIAS  MSE_T_VAR  MSE_TOTAL\n",
       "  0         0.2    0.198980   0.876547   1.075527\n",
       "  0         0.3    0.113098   0.316457   0.429556\n",
       "  0         0.4    0.081825   0.276358   0.358182\n",
       "  0         0.5    0.085708   0.288292   0.374000\n",
       "  0         0.6    0.198010   0.207437   0.405447\n",
       "  0         0.7    0.196531   0.373973   0.570504\n",
       "  0         0.8    0.159501   0.317892   0.477394\n",
       "  0         0.9    0.442942   0.612952   1.055894],\n",
       " [2.5],\n",
       " [   test_sizes  MSE_T_BIAS  MSE_T_VAR  MSE_TOTAL\n",
       "  0         0.2    0.291563   1.920220   2.211783\n",
       "  0         0.3    0.201801   0.949085   1.150886\n",
       "  0         0.4    0.207715   0.732762   0.940477\n",
       "  0         0.5    0.401987   0.996079   1.398066\n",
       "  0         0.6    0.860391   0.808926   1.669317\n",
       "  0         0.7    0.226120   0.700993   0.927114\n",
       "  0         0.8    0.779858   0.747632   1.527490\n",
       "  0         0.9    1.726981   0.433423   2.160405]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
